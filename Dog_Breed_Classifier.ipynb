{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# VGG16, ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras.layers import Input, InputLayer, Convolution2D, MaxPooling2D, Flatten, Dense, Conv2D, Dropout, Lambda, GlobalAveragePooling2D\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# ResNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "# Image\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os, re, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking TensorFlow version and GPU Compatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.4.1\n",
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking and we see that there are no empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique dog breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique breeds: 120\n"
     ]
    }
   ],
   "source": [
    "# List of unique breeds\n",
    "breeds_list = sorted(list(set(labels['breed'])))\n",
    "\n",
    "unique_breeds = len(breeds_list)\n",
    "print(\"Unique breeds:\", unique_breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking sample submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  affenpinscher  afghan_hound  \\\n",
       "0      000621fb3cbb32d8935728e48679680e       0.008333      0.008333   \n",
       "1      00102ee9d8eb90812350685311fe5890       0.008333      0.008333   \n",
       "2      0012a730dfa437f5f3613fb75efcd4ce       0.008333      0.008333   \n",
       "3      001510bc8570bbeee98c8d80c8a95ec1       0.008333      0.008333   \n",
       "4      001a5f3114548acdefa3d4da05474c2e       0.008333      0.008333   \n",
       "...                                 ...            ...           ...   \n",
       "10352  ffeda8623d4eee33c6d1156a2ecbfcf8       0.008333      0.008333   \n",
       "10353  fff1ec9e6e413275984966f745a313b0       0.008333      0.008333   \n",
       "10354  fff74b59b758bbbf13a5793182a9bbe4       0.008333      0.008333   \n",
       "10355  fff7d50d848e8014ac1e9172dc6762a3       0.008333      0.008333   \n",
       "10356  fffbff22c1f51e3dc80c4bf04089545b       0.008333      0.008333   \n",
       "\n",
       "       african_hunting_dog  airedale  american_staffordshire_terrier  \\\n",
       "0                 0.008333  0.008333                        0.008333   \n",
       "1                 0.008333  0.008333                        0.008333   \n",
       "2                 0.008333  0.008333                        0.008333   \n",
       "3                 0.008333  0.008333                        0.008333   \n",
       "4                 0.008333  0.008333                        0.008333   \n",
       "...                    ...       ...                             ...   \n",
       "10352             0.008333  0.008333                        0.008333   \n",
       "10353             0.008333  0.008333                        0.008333   \n",
       "10354             0.008333  0.008333                        0.008333   \n",
       "10355             0.008333  0.008333                        0.008333   \n",
       "10356             0.008333  0.008333                        0.008333   \n",
       "\n",
       "       appenzeller  australian_terrier   basenji    basset  ...  toy_poodle  \\\n",
       "0         0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "1         0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "2         0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "3         0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "4         0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "...            ...                 ...       ...       ...  ...         ...   \n",
       "10352     0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "10353     0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "10354     0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "10355     0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "10356     0.008333            0.008333  0.008333  0.008333  ...    0.008333   \n",
       "\n",
       "       toy_terrier    vizsla  walker_hound  weimaraner  \\\n",
       "0         0.008333  0.008333      0.008333    0.008333   \n",
       "1         0.008333  0.008333      0.008333    0.008333   \n",
       "2         0.008333  0.008333      0.008333    0.008333   \n",
       "3         0.008333  0.008333      0.008333    0.008333   \n",
       "4         0.008333  0.008333      0.008333    0.008333   \n",
       "...            ...       ...           ...         ...   \n",
       "10352     0.008333  0.008333      0.008333    0.008333   \n",
       "10353     0.008333  0.008333      0.008333    0.008333   \n",
       "10354     0.008333  0.008333      0.008333    0.008333   \n",
       "10355     0.008333  0.008333      0.008333    0.008333   \n",
       "10356     0.008333  0.008333      0.008333    0.008333   \n",
       "\n",
       "       welsh_springer_spaniel  west_highland_white_terrier   whippet  \\\n",
       "0                    0.008333                     0.008333  0.008333   \n",
       "1                    0.008333                     0.008333  0.008333   \n",
       "2                    0.008333                     0.008333  0.008333   \n",
       "3                    0.008333                     0.008333  0.008333   \n",
       "4                    0.008333                     0.008333  0.008333   \n",
       "...                       ...                          ...       ...   \n",
       "10352                0.008333                     0.008333  0.008333   \n",
       "10353                0.008333                     0.008333  0.008333   \n",
       "10354                0.008333                     0.008333  0.008333   \n",
       "10355                0.008333                     0.008333  0.008333   \n",
       "10356                0.008333                     0.008333  0.008333   \n",
       "\n",
       "       wire-haired_fox_terrier  yorkshire_terrier  \n",
       "0                     0.008333           0.008333  \n",
       "1                     0.008333           0.008333  \n",
       "2                     0.008333           0.008333  \n",
       "3                     0.008333           0.008333  \n",
       "4                     0.008333           0.008333  \n",
       "...                        ...                ...  \n",
       "10352                 0.008333           0.008333  \n",
       "10353                 0.008333           0.008333  \n",
       "10354                 0.008333           0.008333  \n",
       "10355                 0.008333           0.008333  \n",
       "10356                 0.008333           0.008333  \n",
       "\n",
       "[10357 rows x 121 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways we will be doing this:\n",
    "\n",
    "Part 1. Input > Feature Extraction > Classifier > Predictions\n",
    "\n",
    "Part 2. Input > Neural Network > Predictions\n",
    "\n",
    "The difference is in 2, Feature Extraction + Classification will be done by the Neural Network itself, while 1 will be more \"manual\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 224x224, RGB = 3 channels\n",
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting list of unique breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds_arr = dict(zip(breeds_list, range(unique_breeds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting training+test image data to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training images to array\n",
    "\n",
    "def images_to_array(data_dir, labels, img_size=(224,224,3)):\n",
    "\n",
    "    image_id = labels['id']\n",
    "    images_labels = labels['breed']\n",
    "    data_size = len(image_id)\n",
    "    \n",
    "    X = np.zeros([data_size, img_size[0], img_size[1], img_size[2]], dtype=np.uint8)\n",
    "    y = np.zeros([data_size,1], dtype=np.uint8)\n",
    "    \n",
    "    # Data and labels\n",
    "    for i in tqdm(range(data_size)):\n",
    "        image_name = image_id[i]\n",
    "        img_dir = os.path.join(data_dir, image_name+'.jpg')\n",
    "        img_pixels = load_img(img_dir, target_size=img_size)\n",
    "        X[i] = img_pixels\n",
    "        \n",
    "        image_breed = images_labels[i]\n",
    "        y[i] = breeds_arr[image_breed]\n",
    "    \n",
    "    # One hot encoder\n",
    "    y = to_categorical(y)\n",
    "    \n",
    "    # Shuffle    \n",
    "    ind = np.random.permutation(data_size)\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    print('Data Size: ', X.shape)\n",
    "    print('Label Size: ', y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test images to array\n",
    "\n",
    "def images_to_array2(data_dir, labels, img_size = (224,224,3)):\n",
    "\n",
    "    image_id = labels['id']\n",
    "    data_size = len(image_id)\n",
    "    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(data_size)):\n",
    "        image_name = image_id[i]\n",
    "        img_dir = os.path.join(data_dir, image_name+'.jpg')\n",
    "        img_pixels = tf.keras.preprocessing.image.load_img(img_dir, target_size=img_size)\n",
    "        X[i] = img_pixels\n",
    "        \n",
    "    print('Data Size: ', X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10222/10222 [00:27<00:00, 366.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size:  (10222, 224, 224, 3)\n",
      "Label Size:  (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "\n",
    "X, y = images_to_array('train/', labels, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10357/10357 [00:27<00:00, 376.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size:  (10357, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "test_data = images_to_array2('test/', sample, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction \n",
    "\n",
    "def get_features(model_name, data_preprocessor, input_size, data):\n",
    "    '''\n",
    "    1- Create a feature extractor to extract features from the data.\n",
    "    2- Returns the extracted features and the feature extractor.\n",
    "    '''\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                            input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(data, batch_size=64, verbose=1)\n",
    "    print('Feature shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 46s 227ms/step\n",
      "Feature shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Extracting training features\n",
    "\n",
    "resnet_features_train = get_features(ResNet50, preprocess_input, input_shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 38s 233ms/step\n",
      "Feature shape:  (10357, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Extracting test features\n",
    "\n",
    "resnet_features_test = get_features(ResNet50, preprocess_input, input_shape, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Normal NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a simple NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 2048)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               15480     \n",
      "=================================================================\n",
      "Total params: 277,752\n",
      "Trainable params: 277,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=resnet_features_train.shape[1:])\n",
    "\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "predictions = Dense(units=unique_breeds, activation='softmax')(x) # Classification layer\n",
    "\n",
    "f1 = keras.Model(inputs, predictions, name='DNN')\n",
    "\n",
    "f1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "f1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join('models/', 'resnetfeatures_best_val_loss2.h5'),\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "# If the validation loss doesn't improve, stop training\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9945 - val_loss: 0.9123 - val_accuracy: 0.7615\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9936 - val_loss: 0.9225 - val_accuracy: 0.7605\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9939 - val_loss: 0.9148 - val_accuracy: 0.7693\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9941 - val_loss: 0.9453 - val_accuracy: 0.7664\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9942 - val_loss: 0.9248 - val_accuracy: 0.7693\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9968 - val_loss: 0.9319 - val_accuracy: 0.7664\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9951 - val_loss: 0.9346 - val_accuracy: 0.7566\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9972 - val_loss: 0.9398 - val_accuracy: 0.7683\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9949 - val_loss: 0.9436 - val_accuracy: 0.7615\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9964 - val_loss: 0.9744 - val_accuracy: 0.7595\n"
     ]
    }
   ],
   "source": [
    "f1_h = f1.fit(resnet_features_train, y, \n",
    "              batch_size=bs, \n",
    "              epochs=epoch, \n",
    "              validation_split=0.1, \n",
    "              callbacks=[model_checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_pred = f1.predict(resnet_features_test, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = sample\n",
    "\n",
    "for x in breeds_list:\n",
    "    f1_df[x] = f1_pred[:, breeds_arr[x]]\n",
    "f1_df.to_csv('submission_feature_extraction.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['id'] = labels['id'] + '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split our labels data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Validation shape:\", val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data augmentation\n",
    "\n",
    "\n",
    "We \"create\" more training data from existing data by doing image manipulation (Rotate/Zoom/Scaling/Contrast) (Get more variants of image for neural network to learn)\n",
    "\n",
    "This will help improve the performance of the neural network\n",
    "\n",
    "For more info: https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen for labels\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255, # Scale/Normalize pixel value from range [0,255] to [0,1], RGB coeff in 0-255 too high for model to process\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve our training/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / Validation set\n",
    "\n",
    "bs = 64\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory='train/',\n",
    "    x_col=\"id\",\n",
    "    y_col=\"breed\",\n",
    "    target_size=(224, 224), # Size of each image = 150x150, has to match input_shape\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=bs\n",
    ")\n",
    "\n",
    "validation_set = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=val,\n",
    "    directory='train/',\n",
    "    x_col=\"id\",\n",
    "    y_col=\"breed\",\n",
    "    target_size=(224, 224),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=bs\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    '',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = bs,\n",
    "    classes=['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224, 224, 3])(inputs)\n",
    "x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(units=unique_breeds, activation='softmax')(x) # Classification layer\n",
    "\n",
    "cnn = keras.Model(inputs, predictions, name='CNN')\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View summary of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot = tf.keras.utils.plot_model(cnn, show_shapes=True)\n",
    "display(model_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join('models/', 'cnn_best_val_loss2.h5'),\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "# If the validation loss doesn't improve, stop training\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=9)\n",
    "\n",
    "# If the validation loss doesn't improve, reduce the learning rate to 0.2 times it's previous value\n",
    "\n",
    "# New LR = Old LR * factor\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "step_size_train = training_set.n // bs\n",
    "step_size_val = validation_set.n // bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples // batch size = # of batches\n",
    "# 1 epoch trains # of batches\n",
    "# Weights updated after each batch \n",
    "\n",
    "history = cnn.fit(training_set,\n",
    "          epochs=epochs,\n",
    "          steps_per_epoch=step_size_train,\n",
    "          validation_data=validation_set,\n",
    "          validation_steps=step_size_val,\n",
    "          callbacks=[model_checkpoint, earlystopping, reduce_lr], shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('models/final_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss - Accuracy \n",
    "\n",
    "print(cnn.metrics_names)\n",
    "cnn.evaluate(validation_set, steps=step_size_val, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy + Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_y_pred = cnn.predict(test_set, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ResNet50 (Residual Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tackling vanishing gradient\n",
    "\n",
    "Using pre-trained ResNet model in keras (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set include_top=False, as we will be using our own classification layer\n",
    "# Using imagenet weights\n",
    "\n",
    "resnet = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building classification layer on top of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = keras.Input(shape=input_shape)\n",
    "\n",
    "x = resnet(inputs2)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x) # Dropout layer reduces overfitting\n",
    "\n",
    "x = Dense(units=256,activation='relu')(x) # Rectified Linear Unit - Helping vanishing gradient\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Dense(units=128,activation='relu')(x)\n",
    "x = Dropout(0.35)(x)\n",
    "\n",
    "predictions2 = Dense(units=unique_breeds, activation='softmax')(x) # Sum of Prob = 1 \n",
    "\n",
    "resnet = keras.Model(inputs2, predictions2, name='ResNet')\n",
    "\n",
    "resnet.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) # Multi-class, Labels in one-hot, use categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Summary of the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plot = tf.keras.utils.plot_model(cnn, show_shapes=True)\n",
    "display(model_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join('models/', 'resnet_best_val_loss2.h5'),\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "# If the validation loss doesn't improve, stop training\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=9)\n",
    "\n",
    "# If the validation loss doesn't improve, reduce the learning rate to 0.2 times it's previous value\n",
    "\n",
    "# New LR = Old LR * factor\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = cnn.fit(training_set,\n",
    "          epochs=epochs,\n",
    "          steps_per_epoch=step_size_train,\n",
    "          validation_data=validation_set,\n",
    "          validation_steps=step_size_val,\n",
    "          callbacks=[model_checkpoint, earlystopping, reduce_lr], shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.save('models/final_resnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet.metrics_names)\n",
    "resnet.evaluate(validation_set, steps=step_size_val, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy + Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_y_pred = resnet.predict(test_set, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN:Loss vs Accuracy\\n\")\n",
    "cnn.evaluate(validation_set, steps=step_size_val, verbose=1)\n",
    "print(\"\\n\")\n",
    "print(\"ResNet:Loss vs Accuracy\\n\")\n",
    "resnet.evaluate(validation_set, steps=step_size_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission, opening the sample file to see requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = pd.read_csv('sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = test_set.filenames\n",
    "id_list = []\n",
    "for name in file_list:\n",
    "    m = re.sub('test/', '', name)\n",
    "    m = re.sub('.jpg', '', m)\n",
    "    id_list.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each prediction value to its respective class for each image/file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2['id'] = id_list\n",
    "sample2.iloc[:,1:] = cnn_y_pred\n",
    "sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample2.set_index('id')\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing image features on Tensorboard Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using features extracted using ResNet from Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Involves Dimensionality Reduction (PCA) to display the images on a 3D plane in the projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10357"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resnet_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create feature vectors + metadata (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to tsv file for embedding projector\n",
    "\n",
    "# ResNet features\n",
    "np.savetxt(\"resnet_features_test.tsv\", resnet_features_test, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_arr = f1_pred\n",
    "\n",
    "# Take the highest value/\"predicted\" breed for each test img/file\n",
    "meta_arr = (meta_arr == meta_arr.max(axis=1, keepdims=1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DF - Easier to read\n",
    "meta_df = sample\n",
    "\n",
    "for x in breeds_list:\n",
    "    meta_df[x] = meta_arr[:, breeds_arr[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  affenpinscher  afghan_hound  \\\n",
       "0      000621fb3cbb32d8935728e48679680e              0             0   \n",
       "1      00102ee9d8eb90812350685311fe5890              0             0   \n",
       "2      0012a730dfa437f5f3613fb75efcd4ce              0             0   \n",
       "3      001510bc8570bbeee98c8d80c8a95ec1              0             0   \n",
       "4      001a5f3114548acdefa3d4da05474c2e              0             0   \n",
       "...                                 ...            ...           ...   \n",
       "10352  ffeda8623d4eee33c6d1156a2ecbfcf8              0             0   \n",
       "10353  fff1ec9e6e413275984966f745a313b0              0             0   \n",
       "10354  fff74b59b758bbbf13a5793182a9bbe4              0             0   \n",
       "10355  fff7d50d848e8014ac1e9172dc6762a3              0             0   \n",
       "10356  fffbff22c1f51e3dc80c4bf04089545b              0             0   \n",
       "\n",
       "       african_hunting_dog  airedale  american_staffordshire_terrier  \\\n",
       "0                        0         0                               0   \n",
       "1                        0         0                               0   \n",
       "2                        0         0                               0   \n",
       "3                        0         0                               0   \n",
       "4                        0         0                               0   \n",
       "...                    ...       ...                             ...   \n",
       "10352                    0         0                               0   \n",
       "10353                    0         0                               0   \n",
       "10354                    0         0                               0   \n",
       "10355                    0         0                               0   \n",
       "10356                    0         0                               0   \n",
       "\n",
       "       appenzeller  australian_terrier  basenji  basset  ...  toy_poodle  \\\n",
       "0                0                   0        0       0  ...           0   \n",
       "1                0                   0        0       0  ...           0   \n",
       "2                0                   0        0       0  ...           0   \n",
       "3                0                   0        0       0  ...           0   \n",
       "4                0                   0        0       0  ...           0   \n",
       "...            ...                 ...      ...     ...  ...         ...   \n",
       "10352            0                   0        0       0  ...           0   \n",
       "10353            0                   0        0       0  ...           0   \n",
       "10354            0                   0        0       0  ...           0   \n",
       "10355            0                   0        0       0  ...           0   \n",
       "10356            0                   0        0       0  ...           0   \n",
       "\n",
       "       toy_terrier  vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0                0       0             0           0                       0   \n",
       "1                0       0             0           0                       0   \n",
       "2                0       0             0           0                       0   \n",
       "3                0       0             0           0                       0   \n",
       "4                0       0             0           0                       0   \n",
       "...            ...     ...           ...         ...                     ...   \n",
       "10352            0       0             0           0                       0   \n",
       "10353            0       0             0           1                       0   \n",
       "10354            0       0             0           0                       0   \n",
       "10355            0       0             0           0                       0   \n",
       "10356            0       0             0           0                       0   \n",
       "\n",
       "       west_highland_white_terrier  whippet  wire-haired_fox_terrier  \\\n",
       "0                                0        0                        0   \n",
       "1                                0        0                        0   \n",
       "2                                0        0                        0   \n",
       "3                                0        0                        0   \n",
       "4                                0        0                        0   \n",
       "...                            ...      ...                      ...   \n",
       "10352                            0        0                        0   \n",
       "10353                            0        0                        0   \n",
       "10354                            0        0                        0   \n",
       "10355                            0        0                        0   \n",
       "10356                            0        0                        0   \n",
       "\n",
       "       yorkshire_terrier  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "10352                  0  \n",
       "10353                  0  \n",
       "10354                  0  \n",
       "10355                  0  \n",
       "10356                  0  \n",
       "\n",
       "[10357 rows x 121 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing OHE array\n",
    "\n",
    "# Label each img/file to its predicted breed\n",
    "def reverse_OHE(row):\n",
    "    for c in meta_df.columns:\n",
    "        if row[c]==1:\n",
    "            return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_meta_df = pd.DataFrame(meta_df.apply(reverse_OHE, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining img id \n",
    "reverse_meta_df = reverse_meta_df.join(meta_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename headers\n",
    "reverse_meta_df.columns = ['breed', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japanese_spaniel</td>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samoyed</td>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english_setter</td>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pug</td>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tibetan_terrier</td>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>standard_poodle</td>\n",
       "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>weimaraner</td>\n",
       "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>dhole</td>\n",
       "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>lhasa</td>\n",
       "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>scottish_deerhound</td>\n",
       "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    breed                                id\n",
       "0        japanese_spaniel  000621fb3cbb32d8935728e48679680e\n",
       "1                 samoyed  00102ee9d8eb90812350685311fe5890\n",
       "2          english_setter  0012a730dfa437f5f3613fb75efcd4ce\n",
       "3                     pug  001510bc8570bbeee98c8d80c8a95ec1\n",
       "4         tibetan_terrier  001a5f3114548acdefa3d4da05474c2e\n",
       "...                   ...                               ...\n",
       "10352     standard_poodle  ffeda8623d4eee33c6d1156a2ecbfcf8\n",
       "10353          weimaraner  fff1ec9e6e413275984966f745a313b0\n",
       "10354               dhole  fff74b59b758bbbf13a5793182a9bbe4\n",
       "10355               lhasa  fff7d50d848e8014ac1e9172dc6762a3\n",
       "10356  scottish_deerhound  fffbff22c1f51e3dc80c4bf04089545b\n",
       "\n",
       "[10357 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to tsv file \n",
    "\n",
    "metadata = reverse_meta_df[['id', 'breed']].to_csv('metadata.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create sprite image (Collage) to be displayed on the projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! magick montage train/*.jpg -tile 105x105 -geometry 50x50! sprite.jpg\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projector_config.pbtxt should look like this\n",
    "\n",
    "with open('projector_config.pbtxt', 'w') as file:\n",
    "    file.write('embeddings { tensor_path: \"resnet_features_test.tsv\" metadata_path: \"metadata.tsv\" sprite { image_path: \"sprite.jpg\" single_image_dim: 50 single_image_dim: 50 } }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tensorboard locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! tensorboard --logdir logs/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open: http://localhost:6006/#projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\n",
    "\n",
    "[2] https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624\n",
    "\n",
    "[3] https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/#:~:text=The%20rectified%20linear%20activation%20function,otherwise%2C%20it%20will%20output%20zero.&text=The%20rectified%20linear%20activation%20function%20overcomes%20the%20vanishing%20gradient%20problem,learn%20faster%20and%20perform%20better\n",
    "\n",
    "[4] https://medium.com/@kumon/visualizing-image-feature-vectors-through-tensorboard-b850ce1be7f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
